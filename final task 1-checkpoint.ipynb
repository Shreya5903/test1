{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbdbb84b-b742-4ba3-b82d-b1c7290bd564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in c:\\python312\\lib\\site-packages (0.8.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\shrey\\appdata\\roaming\\python\\python312\\site-packages (2.2.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\python312\\lib\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\python312\\lib\\site-packages (from google-generativeai) (2.28.1)\n",
      "Requirement already satisfied: google-api-python-client in c:\\python312\\lib\\site-packages (from google-generativeai) (2.187.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\python312\\lib\\site-packages (from google-generativeai) (2.43.0)\n",
      "Requirement already satisfied: protobuf in c:\\python312\\lib\\site-packages (from google-generativeai) (5.29.5)\n",
      "Requirement already satisfied: pydantic in c:\\users\\shrey\\appdata\\roaming\\python\\python312\\site-packages (from google-generativeai) (2.11.2)\n",
      "Requirement already satisfied: tqdm in c:\\python312\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\python312\\lib\\site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\python312\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in c:\\python312\\lib\\site-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\shrey\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\python312\\lib\\site-packages (from google-api-core->google-generativeai) (1.72.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\shrey\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\python312\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (6.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\python312\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\python312\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\python312\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\python312\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\python312\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\python312\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\python312\\lib\\site-packages (from pydantic->google-generativeai) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\python312\\lib\\site-packages (from pydantic->google-generativeai) (0.4.0)\n",
      "Requirement already satisfied: colorama in c:\\python312\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\python312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\python312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in c:\\python312\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\python312\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shrey\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shrey\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shrey\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shrey\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2024.7.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install google-generativeai pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c90fba67-bbcb-4c6b-a773-8c0285682941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini API Ready!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Use Gemini API key directly\n",
    "GEMINI_API_KEY = \"AIzaSyATYgczfXXfe8kfwwgeALh-gD9kJ1wgk6w\"\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "print(\"Gemini API Ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1272a45d-f89a-4f0d-a396-8fda6c9a99e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"yelp.csv\")\n",
    "\n",
    "# Show first 5 rows\n",
    "df.head()\n",
    "df_200 = df.sample(n=200, random_state=42)\n",
    "df_200 = df_200.fillna(\"Unknown\")\n",
    "\n",
    "df_200.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c411118d-8287-4d04-8eaa-ab7f526b41b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_1 = \"\"\"\n",
    "You are an expert Yelp rating auditor.\n",
    "Read the review below and return ONLY valid JSON in EXACTLY this format:\n",
    "\n",
    "{{\n",
    "  \"predicted_stars\": <integer 1-5>,\n",
    "  \"explanation\": \"<one short sentence>\"\n",
    "}}\n",
    "\n",
    "Rules:\n",
    "- predicted_stars must be an integer between 1 and 5.\n",
    "- explanation: 6–20 words max, mention the main cue (e.g., \"positive language\", \"poor service\").\n",
    "- Do NOT output anything other than the JSON object (no code blocks, no commentary).\n",
    "- Do not hallucinate facts not present in the text.\n",
    "\n",
    "Review:\n",
    "\"{review_text}\"\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7c75e85-eec4-4eac-bab9-b0586ef0d1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(\"models/gemini-2.5-flash\")\n",
    "\n",
    "\n",
    "def get_response(prompt):\n",
    "    response = model.generate_content([prompt])  # LIST input\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33ee89df-eb85-44d8-b1e4-805e10dd9f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompt_1(review_text):\n",
    "    prompt = PROMPT_1.format(review_text=review_text)\n",
    "    raw_output = get_response(prompt)\n",
    "    return raw_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47fcc1fa-c542-4cd0-802b-7f7390650134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "      <th>prompt1_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3787</th>\n",
       "      <td>Went here while on vacation in Phoneix based on seeing it on Man vs Food. Could not have been more impressed. Food was amazing. Far above expectations.  The torta was huge and delicious. Would highly recommend it to anyone looking for a fantastic authentic meal at a good price!</td>\n",
       "      <td>5</td>\n",
       "      <td>```json\\n{\\n  \"predicted_stars\": 5,\\n  \"explanation\": \"The reviewer used overwhelmingly positive language and strongly recommended the fantastic food.\"\\n}\\n```</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6033</th>\n",
       "      <td>So I was pretty excited about this burger joint opening since it's President Obama's favorite... \\nThe burger was good. Not great, not bland, just okay. My biggest hang up with this restaurant are the prices! Skip the beverage... it's very over priced. I was also not impressed with the fries- regular or cajun. They were pretty average as well. Stick with the burger and skip the rest is my suggestion to you.</td>\n",
       "      <td>2</td>\n",
       "      <td>{\\n  \"predicted_stars\": 2,\\n  \"explanation\": \"The review expresses strong dissatisfaction with overpriced items and average food quality, despite an okay burger.\"\\n}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>My wife and I live around the corner, hadn't eaten here in a few months. We got food for take out, Mongolian beef,kung po chicken,pad Thai noodles.  Mongolian beef, there were more white onions then scallions and it was very bland. Kung po chicken,lots of white meat chicken the whole dish only had one peanut and the taste of this dish was non existent. Very very Blah... Pad Thai noodles,the dish was dry and came out of the container in one giant clump. It tasted like plain noodles, i was gla...</td>\n",
       "      <td>1</td>\n",
       "      <td>```json\\n{\\n  \"predicted_stars\": 1,\\n  \"explanation\": \"The review expresses extreme disappointment due to bland, dry, and unappetizing food quality across multiple dishes.\"\\n}\\n```</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5674</th>\n",
       "      <td>I don't often review places on Yelp because of the time commitment and because usually I am just looking for a good bite to eat. This time, though I feel I should if not to balance the ridiculous number of 4 and 5 stars bouncing around for this place.\\nThe food was decent, and the atmosphere OK but seriously, how can this place cost as much as it does ($60+ for two people eating light)?? And how are people fawning all over it? I don't like to complain about a good meal, and indeed this meal ...</td>\n",
       "      <td>2</td>\n",
       "      <td>```json\\n{\\n  \"predicted_stars\": 2,\\n  \"explanation\": \"Despite good service, the high cost, poor value, and pretentious atmosphere led to a negative experience.\"\\n}\\n```</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9149</th>\n",
       "      <td>The Harkins Camelview 5 gives Arizonans the unique opportunity to see movies that are normally reserved for screens in NY and CA. Without this theater there would be very little chance to see independent or foreign films in Phoenix. I give a lot of credit to Dan Harkins for keeping this theater open. He certainly can't  make much money at this location. It's financially  impractical to keep such a small theater operating on such prime real estate. This just shows Dan Harkin's commitment to s...</td>\n",
       "      <td>5</td>\n",
       "      <td>{\\n  \"predicted_stars\": 5,\\n  \"explanation\": \"The review expresses strong gratitude for the theater's unique film selection and owner's dedication.\"\\n}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     text  \\\n",
       "3787                                                                                                                                                                                                                               Went here while on vacation in Phoneix based on seeing it on Man vs Food. Could not have been more impressed. Food was amazing. Far above expectations.  The torta was huge and delicious. Would highly recommend it to anyone looking for a fantastic authentic meal at a good price!   \n",
       "6033                                                                                           So I was pretty excited about this burger joint opening since it's President Obama's favorite... \\nThe burger was good. Not great, not bland, just okay. My biggest hang up with this restaurant are the prices! Skip the beverage... it's very over priced. I was also not impressed with the fries- regular or cajun. They were pretty average as well. Stick with the burger and skip the rest is my suggestion to you.   \n",
       "321   My wife and I live around the corner, hadn't eaten here in a few months. We got food for take out, Mongolian beef,kung po chicken,pad Thai noodles.  Mongolian beef, there were more white onions then scallions and it was very bland. Kung po chicken,lots of white meat chicken the whole dish only had one peanut and the taste of this dish was non existent. Very very Blah... Pad Thai noodles,the dish was dry and came out of the container in one giant clump. It tasted like plain noodles, i was gla...   \n",
       "5674  I don't often review places on Yelp because of the time commitment and because usually I am just looking for a good bite to eat. This time, though I feel I should if not to balance the ridiculous number of 4 and 5 stars bouncing around for this place.\\nThe food was decent, and the atmosphere OK but seriously, how can this place cost as much as it does ($60+ for two people eating light)?? And how are people fawning all over it? I don't like to complain about a good meal, and indeed this meal ...   \n",
       "9149  The Harkins Camelview 5 gives Arizonans the unique opportunity to see movies that are normally reserved for screens in NY and CA. Without this theater there would be very little chance to see independent or foreign films in Phoenix. I give a lot of credit to Dan Harkins for keeping this theater open. He certainly can't  make much money at this location. It's financially  impractical to keep such a small theater operating on such prime real estate. This just shows Dan Harkin's commitment to s...   \n",
       "\n",
       "      stars  \\\n",
       "3787      5   \n",
       "6033      2   \n",
       "321       1   \n",
       "5674      2   \n",
       "9149      5   \n",
       "\n",
       "                                                                                                                                                                            prompt1_output  \n",
       "3787                       ```json\\n{\\n  \"predicted_stars\": 5,\\n  \"explanation\": \"The reviewer used overwhelmingly positive language and strongly recommended the fantastic food.\"\\n}\\n```  \n",
       "6033                 {\\n  \"predicted_stars\": 2,\\n  \"explanation\": \"The review expresses strong dissatisfaction with overpriced items and average food quality, despite an okay burger.\"\\n}  \n",
       "321   ```json\\n{\\n  \"predicted_stars\": 1,\\n  \"explanation\": \"The review expresses extreme disappointment due to bland, dry, and unappetizing food quality across multiple dishes.\"\\n}\\n```  \n",
       "5674             ```json\\n{\\n  \"predicted_stars\": 2,\\n  \"explanation\": \"Despite good service, the high cost, poor value, and pretentious atmosphere led to a negative experience.\"\\n}\\n```  \n",
       "9149                               {\\n  \"predicted_stars\": 5,\\n  \"explanation\": \"The review expresses strong gratitude for the theater's unique film selection and owner's dedication.\"\\n}  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = df_200.sample(5, random_state=42).copy()\n",
    "sample_df[\"prompt1_output\"] = sample_df[\"text\"].apply(run_prompt_1)\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "sample_df[[\"text\", \"stars\", \"prompt1_output\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "306a3489-d04d-4e51-996b-b4bb46b18f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "eval_df = df_200.sample(50, random_state=123).reset_index(drop=True)\n",
    "eval_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4185884c-5abd-40a3-b767-149b6c5e9d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Prompt 1 for row 1/50...\n",
      "Running Prompt 1 for row 2/50...\n",
      "Running Prompt 1 for row 3/50...\n",
      "Running Prompt 1 for row 4/50...\n",
      "Running Prompt 1 for row 5/50...\n",
      "Running Prompt 1 for row 6/50...\n",
      "Running Prompt 1 for row 7/50...\n",
      "Running Prompt 1 for row 8/50...\n",
      "Running Prompt 1 for row 9/50...\n",
      "Running Prompt 1 for row 10/50...\n",
      "Running Prompt 1 for row 11/50...\n",
      "Running Prompt 1 for row 12/50...\n",
      "Running Prompt 1 for row 13/50...\n",
      "Running Prompt 1 for row 14/50...\n",
      "Running Prompt 1 for row 15/50...\n",
      "Running Prompt 1 for row 16/50...\n",
      "Running Prompt 1 for row 17/50...\n",
      "Running Prompt 1 for row 18/50...\n",
      "Running Prompt 1 for row 19/50...\n",
      "Running Prompt 1 for row 20/50...\n",
      "Running Prompt 1 for row 21/50...\n",
      "Running Prompt 1 for row 22/50...\n",
      "Running Prompt 1 for row 23/50...\n",
      "Running Prompt 1 for row 24/50...\n",
      "Running Prompt 1 for row 25/50...\n",
      "Running Prompt 1 for row 26/50...\n",
      "Running Prompt 1 for row 27/50...\n",
      "Running Prompt 1 for row 28/50...\n",
      "Running Prompt 1 for row 29/50...\n",
      "Running Prompt 1 for row 30/50...\n",
      "Running Prompt 1 for row 31/50...\n",
      "Running Prompt 1 for row 32/50...\n",
      "Running Prompt 1 for row 33/50...\n",
      "Running Prompt 1 for row 34/50...\n",
      "Running Prompt 1 for row 35/50...\n",
      "Running Prompt 1 for row 36/50...\n",
      "Running Prompt 1 for row 37/50...\n",
      "Running Prompt 1 for row 38/50...\n",
      "Running Prompt 1 for row 39/50...\n",
      "Running Prompt 1 for row 40/50...\n",
      "Running Prompt 1 for row 41/50...\n",
      "Running Prompt 1 for row 42/50...\n",
      "Running Prompt 1 for row 43/50...\n",
      "Running Prompt 1 for row 44/50...\n",
      "Running Prompt 1 for row 45/50...\n",
      "Running Prompt 1 for row 46/50...\n",
      "Running Prompt 1 for row 47/50...\n",
      "Running Prompt 1 for row 48/50...\n",
      "Running Prompt 1 for row 49/50...\n",
      "Running Prompt 1 for row 50/50...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "p1_outputs = []\n",
    "\n",
    "for i, txt in enumerate(eval_df[\"text\"]):\n",
    "    print(f\"Running Prompt 1 for row {i+1}/{len(eval_df)}...\")\n",
    "    try:\n",
    "        out = run_prompt_1(txt)\n",
    "    except Exception as e:\n",
    "        print(\"Error on row\", i, \":\", e)\n",
    "        out = None\n",
    "    p1_outputs.append(out)\n",
    "    \n",
    "    # Sleep ~7 seconds to stay under 10 requests per minute\n",
    "    time.sleep(7)\n",
    "\n",
    "eval_df[\"p1_output\"] = p1_outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "603d4685-e6b7-4265-96ab-e06950a8f5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def parse_json_output(output):\n",
    "    try:\n",
    "        # Sometimes model adds code fences like ```json\n",
    "        cleaned = output.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "        return json.loads(cleaned), True\n",
    "    except:\n",
    "        return None, False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17bbac56-0d52-4317-b9a8-58553238f92d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.56, 1.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_results = []\n",
    "validity_flags = []\n",
    "predicted_stars = []\n",
    "\n",
    "for out in eval_df[\"p1_output\"]:\n",
    "    result, is_valid = parse_json_output(out)\n",
    "    validity_flags.append(is_valid)\n",
    "    \n",
    "    if is_valid:\n",
    "        predicted_stars.append(result.get(\"predicted_stars\", None))\n",
    "    else:\n",
    "        predicted_stars.append(None)\n",
    "\n",
    "eval_df[\"p1_valid_json\"] = validity_flags\n",
    "eval_df[\"p1_predicted_stars\"] = predicted_stars\n",
    "\n",
    "correct = (eval_df[\"stars\"] == eval_df[\"p1_predicted_stars\"]).sum()\n",
    "accuracy_p1 = correct / len(eval_df)\n",
    "json_validity_p1 = eval_df[\"p1_valid_json\"].mean()\n",
    "accuracy_p1, json_validity_p1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24eaa597-96c1-4c31-908f-f1542415506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_2 = \"\"\"\n",
    "You are an expert Yelp rating auditor.\n",
    "Study the complex examples below and then rate the new review.\n",
    "Return ONLY valid JSON in EXACTLY this format:\n",
    "\n",
    "{{\n",
    "  \"predicted_stars\": <integer 1-5>,\n",
    "  \"explanation\": \"<one short sentence>\"\n",
    "}}\n",
    "\n",
    "Examples:\n",
    "\n",
    "Example 1:\n",
    "Review: \"The appetizers were delicious but the main course arrived cold. The staff apologized, but the long wait ruined the experience.\"\n",
    "Stars: 2\n",
    "\n",
    "Example 2:\n",
    "Review: \"Great location and cozy atmosphere. The coffee was above average, but the pastries were dry. Still, I’d visit again for the vibe.\"\n",
    "Stars: 4\n",
    "\n",
    "Example 3:\n",
    "Review: \"Absolute disaster. The server ignored us for 30 minutes, the food was bland, and they messed up our bill twice.\"\n",
    "Stars: 1\n",
    "\n",
    "Example 4:\n",
    "Review: \"Food tasted fine, portion sizes were okay, service was neither slow nor fast. Very average overall, nothing stood out.\"\n",
    "Stars: 3\n",
    "\n",
    "Example 5:\n",
    "Review: \"Fantastic! Fresh ingredients, fast service, fair prices, and the staff went out of their way to make us comfortable.\"\n",
    "Stars: 5\n",
    "\n",
    "Instructions:\n",
    "- Use the examples as a guide to map sentiment to stars.\n",
    "- predicted_stars must be an integer from 1 to 5.\n",
    "- explanation should be 6–20 words and mention the main reason.\n",
    "- Do NOT output anything other than the JSON object.\n",
    "- Do NOT include code blocks.\n",
    "\n",
    "Now classify this review:\n",
    "\n",
    "\"{review_text}\"\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e75e4b12-1c9c-4fdb-ac11-dc9294fce9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompt_2(review_text):\n",
    "    prompt = PROMPT_2.format(review_text=review_text)\n",
    "    raw_output = get_response(prompt)   # uses same get_response as Prompt 1\n",
    "    return raw_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d816f93-76e9-4de8-af25-114a78860728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n  \"predicted_stars\": 3,\\n  \"explanation\": \"The good food is a positive, but the slow service significantly detracts from the experience.\"\\n}\\n```'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_prompt_2(\"The food was good but service was slow.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fee63a02-fed5-4c57-b009-c10f8b06977e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Prompt 2 for row 1/50...\n",
      "Running Prompt 2 for row 2/50...\n",
      "Running Prompt 2 for row 3/50...\n",
      "Running Prompt 2 for row 4/50...\n",
      "Running Prompt 2 for row 5/50...\n",
      "Running Prompt 2 for row 6/50...\n",
      "Running Prompt 2 for row 7/50...\n",
      "Running Prompt 2 for row 8/50...\n",
      "Running Prompt 2 for row 9/50...\n",
      "Running Prompt 2 for row 10/50...\n",
      "Running Prompt 2 for row 11/50...\n",
      "Running Prompt 2 for row 12/50...\n",
      "Running Prompt 2 for row 13/50...\n",
      "Running Prompt 2 for row 14/50...\n",
      "Running Prompt 2 for row 15/50...\n",
      "Running Prompt 2 for row 16/50...\n",
      "Running Prompt 2 for row 17/50...\n",
      "Running Prompt 2 for row 18/50...\n",
      "Running Prompt 2 for row 19/50...\n",
      "Running Prompt 2 for row 20/50...\n",
      "Running Prompt 2 for row 21/50...\n",
      "Running Prompt 2 for row 22/50...\n",
      "Running Prompt 2 for row 23/50...\n",
      "Running Prompt 2 for row 24/50...\n",
      "Running Prompt 2 for row 25/50...\n",
      "Running Prompt 2 for row 26/50...\n",
      "Running Prompt 2 for row 27/50...\n",
      "Running Prompt 2 for row 28/50...\n",
      "Running Prompt 2 for row 29/50...\n",
      "Running Prompt 2 for row 30/50...\n",
      "Running Prompt 2 for row 31/50...\n",
      "Running Prompt 2 for row 32/50...\n",
      "Running Prompt 2 for row 33/50...\n",
      "Running Prompt 2 for row 34/50...\n",
      "Running Prompt 2 for row 35/50...\n",
      "Running Prompt 2 for row 36/50...\n",
      "Running Prompt 2 for row 37/50...\n",
      "Running Prompt 2 for row 38/50...\n",
      "Running Prompt 2 for row 39/50...\n",
      "Running Prompt 2 for row 40/50...\n",
      "Running Prompt 2 for row 41/50...\n",
      "Running Prompt 2 for row 42/50...\n",
      "Running Prompt 2 for row 43/50...\n",
      "Running Prompt 2 for row 44/50...\n",
      "Running Prompt 2 for row 45/50...\n",
      "Running Prompt 2 for row 46/50...\n",
      "Running Prompt 2 for row 47/50...\n",
      "Running Prompt 2 for row 48/50...\n",
      "Running Prompt 2 for row 49/50...\n",
      "Running Prompt 2 for row 50/50...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "p2_outputs = []\n",
    "\n",
    "for i, txt in enumerate(eval_df[\"text\"]):\n",
    "    print(f\"Running Prompt 2 for row {i+1}/{len(eval_df)}...\")\n",
    "    try:\n",
    "        out = run_prompt_2(txt)\n",
    "    except Exception as e:\n",
    "        print(\"Error on row\", i, \":\", e)\n",
    "        out = None\n",
    "    p2_outputs.append(out)\n",
    "    \n",
    "    time.sleep(7)  # respect free-tier rate limit\n",
    "\n",
    "eval_df[\"p2_output\"] = p2_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92601d37-9453-4e6d-b92d-bd02b551e46a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.52, 0.96)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2_valid_flags = []\n",
    "p2_pred_stars = []\n",
    "\n",
    "for out in eval_df[\"p2_output\"]:\n",
    "    result, is_valid = parse_json_output(out)\n",
    "    p2_valid_flags.append(is_valid)\n",
    "    \n",
    "    if is_valid:\n",
    "        p2_pred_stars.append(result.get(\"predicted_stars\", None))\n",
    "    else:\n",
    "        p2_pred_stars.append(None)\n",
    "\n",
    "eval_df[\"p2_valid_json\"] = p2_valid_flags\n",
    "eval_df[\"p2_predicted_stars\"] = p2_pred_stars\n",
    "\n",
    "correct_p2 = (eval_df[\"stars\"] == eval_df[\"p2_predicted_stars\"]).sum()\n",
    "accuracy_p2 = correct_p2 / len(eval_df)\n",
    "json_validity_p2 = eval_df[\"p2_valid_json\"].mean()\n",
    "\n",
    "accuracy_p2, json_validity_p2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c215aeb8-a135-4003-a9c4-f92fa0021372",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_3 = \"\"\"\n",
    "You are a Yelp Rating Evaluator. Use the rubric below and return ONLY valid JSON in EXACTLY this format:\n",
    "\n",
    "{{\n",
    "  \"predicted_stars\": <integer 1-5>,\n",
    "  \"explanation\": \"<one short sentence>\"\n",
    "}}\n",
    "\n",
    "Rubric (how to choose the rating):\n",
    "- 1 star  = Strong negative sentiment, serious complaints, very bad experience.\n",
    "- 2 stars = Mostly negative, clear problems, but not completely horrible.\n",
    "- 3 stars = Mixed or neutral; some positives and some negatives, or very weak sentiment.\n",
    "- 4 stars = Mostly positive with minor issues.\n",
    "- 5 stars = Strongly positive, enthusiastic, clear praise or recommendation.\n",
    "\n",
    "Rules:\n",
    "- Base your decision ONLY on the review text.\n",
    "- If the sentiment is mixed, choose the rating that matches the dominant tone.\n",
    "- predicted_stars must be an integer from 1 to 5.\n",
    "- explanation (6–20 words) must mention the main reason (e.g., good food, bad service, slow staff).\n",
    "- Do NOT output anything other than the JSON object.\n",
    "- Do NOT include code blocks.\n",
    "\n",
    "Now classify this review:\n",
    "\n",
    "\"{review_text}\"\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e49065dd-5507-42b2-ae4f-37c20e6c06a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompt_3(review_text):\n",
    "    prompt = PROMPT_3.format(review_text=review_text)\n",
    "    raw_output = get_response(prompt)\n",
    "    return raw_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1435f5e2-d75a-47a6-a229-25e8e5f61419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"predicted_stars\": 3,\n",
      "  \"explanation\": \"The good food was balanced by the negative experience of slow service.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(run_prompt_3(\"The food was good but the service was slow.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64924a60-37ac-45ae-97d2-eb1484136fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Prompt 3 for row 1/50...\n",
      "Running Prompt 3 for row 2/50...\n",
      "Running Prompt 3 for row 3/50...\n",
      "Running Prompt 3 for row 4/50...\n",
      "Running Prompt 3 for row 5/50...\n",
      "Running Prompt 3 for row 6/50...\n",
      "Running Prompt 3 for row 7/50...\n",
      "Running Prompt 3 for row 8/50...\n",
      "Running Prompt 3 for row 9/50...\n",
      "Running Prompt 3 for row 10/50...\n",
      "Running Prompt 3 for row 11/50...\n",
      "Running Prompt 3 for row 12/50...\n",
      "Running Prompt 3 for row 13/50...\n",
      "Running Prompt 3 for row 14/50...\n",
      "Running Prompt 3 for row 15/50...\n",
      "Running Prompt 3 for row 16/50...\n",
      "Running Prompt 3 for row 17/50...\n",
      "Running Prompt 3 for row 18/50...\n",
      "Running Prompt 3 for row 19/50...\n",
      "Running Prompt 3 for row 20/50...\n",
      "Running Prompt 3 for row 21/50...\n",
      "Running Prompt 3 for row 22/50...\n",
      "Running Prompt 3 for row 23/50...\n",
      "Running Prompt 3 for row 24/50...\n",
      "Running Prompt 3 for row 25/50...\n",
      "Running Prompt 3 for row 26/50...\n",
      "Running Prompt 3 for row 27/50...\n",
      "Running Prompt 3 for row 28/50...\n",
      "Running Prompt 3 for row 29/50...\n",
      "Running Prompt 3 for row 30/50...\n",
      "Running Prompt 3 for row 31/50...\n",
      "Running Prompt 3 for row 32/50...\n",
      "Running Prompt 3 for row 33/50...\n",
      "Running Prompt 3 for row 34/50...\n",
      "Running Prompt 3 for row 35/50...\n",
      "Running Prompt 3 for row 36/50...\n",
      "Running Prompt 3 for row 37/50...\n",
      "Running Prompt 3 for row 38/50...\n",
      "Running Prompt 3 for row 39/50...\n",
      "Running Prompt 3 for row 40/50...\n",
      "Running Prompt 3 for row 41/50...\n",
      "Running Prompt 3 for row 42/50...\n",
      "Running Prompt 3 for row 43/50...\n",
      "Running Prompt 3 for row 44/50...\n",
      "Running Prompt 3 for row 45/50...\n",
      "Running Prompt 3 for row 46/50...\n",
      "Running Prompt 3 for row 47/50...\n",
      "Running Prompt 3 for row 48/50...\n",
      "Running Prompt 3 for row 49/50...\n",
      "Running Prompt 3 for row 50/50...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "p3_outputs = []\n",
    "\n",
    "for i, txt in enumerate(eval_df[\"text\"]):\n",
    "    print(f\"Running Prompt 3 for row {i+1}/{len(eval_df)}...\")\n",
    "    try:\n",
    "        out = run_prompt_3(txt)\n",
    "    except Exception as e:\n",
    "        print(\"Error on row\", i, \":\", e)\n",
    "        out = None\n",
    "    p3_outputs.append(out)\n",
    "    \n",
    "    time.sleep(7)  # respect free-tier rate limit\n",
    "\n",
    "eval_df[\"p3_output\"] = p3_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f50a3c74-5bc0-4410-b451-a8217f375c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.58, 1.0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p3_valid_flags = []\n",
    "p3_pred_stars = []\n",
    "\n",
    "for out in eval_df[\"p3_output\"]:\n",
    "    result, is_valid = parse_json_output(out)\n",
    "    p3_valid_flags.append(is_valid)\n",
    "    \n",
    "    if is_valid:\n",
    "        p3_pred_stars.append(result.get(\"predicted_stars\", None))\n",
    "    else:\n",
    "        p3_pred_stars.append(None)\n",
    "\n",
    "eval_df[\"p3_valid_json\"] = p3_valid_flags\n",
    "eval_df[\"p3_predicted_stars\"] = p3_pred_stars\n",
    "\n",
    "correct_p3 = (eval_df[\"stars\"] == eval_df[\"p3_predicted_stars\"]).sum()\n",
    "accuracy_p3 = correct_p3 / len(eval_df)\n",
    "json_validity_p3 = eval_df[\"p3_valid_json\"].mean()\n",
    "\n",
    "accuracy_p3, json_validity_p3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3acf37f6-5c4b-4ce5-8735-df14ac4d16c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_4 = \"\"\"\n",
    "You are a Yelp review rating classifier. Your job is to decide the correct rating (1–5 stars) STRICTLY based on the text.\n",
    "\n",
    "Return ONLY valid JSON in EXACTLY this format:\n",
    "\n",
    "{{\n",
    "  \"predicted_stars\": <integer 1–5>,\n",
    "  \"explanation\": \"<short reason>\"\n",
    "}}\n",
    "\n",
    "Follow this process:\n",
    "\n",
    "1. Internally identify:\n",
    "   - The sentiment (positive, mixed, negative)\n",
    "   - Strength of emotion (weak / moderate / strong)\n",
    "   - Any explicit praise or complaints\n",
    "   - Any indicators of service, food, price, ambience\n",
    "\n",
    "2. Internally decide the correct rating using these rules:\n",
    "   - Strong negative emotion → 1 star\n",
    "   - Mostly negative → 2 stars\n",
    "   - Mixed or neutral → 3 stars\n",
    "   - Mostly positive → 4 stars\n",
    "   - Strongly positive → 5 stars\n",
    "\n",
    "3. IMPORTANT: Do NOT reveal your reasoning. Only output the final JSON.\n",
    "\n",
    "Rules:\n",
    "- predicted_stars must be an integer 1–5.\n",
    "- explanation must be 6–18 words summarizing the main reason.\n",
    "- No code blocks, no markdown, no extra text.\n",
    "\n",
    "Review:\n",
    "\"{review_text}\"\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4eb0eb0-7f6b-40ba-9907-4da4a5bf5c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompt_4(review_text):\n",
    "    prompt = PROMPT_4.format(review_text=review_text)\n",
    "    raw_output = get_response(prompt)\n",
    "    return raw_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c390e8c5-9ff0-4436-b692-7c747cca0497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predicted_stars\": 5, \"explanation\": \"Amazing prices, great atmosphere, and incredibly attentive wait staff made for an excellent experience.\"}\n"
     ]
    }
   ],
   "source": [
    "print(run_prompt_4(\"Definitely come for Happy hour! Prices are amazing, sake bombers for $3...Great atmosphere and wait staff was incredibly nice and right on to all of our needs, didn't have to ask for a thing They were always spot on...Place gets crowded in the evening especially if you plan on sitting outside. I only wish there were one in Apollo Beach or Brandon!\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86875716-20be-4bd6-b67d-5ced6000a6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Prompt 4 for row 1/50...\n",
      "Running Prompt 4 for row 2/50...\n",
      "Running Prompt 4 for row 3/50...\n",
      "Running Prompt 4 for row 4/50...\n",
      "Running Prompt 4 for row 5/50...\n",
      "Running Prompt 4 for row 6/50...\n",
      "Running Prompt 4 for row 7/50...\n",
      "Running Prompt 4 for row 8/50...\n",
      "Running Prompt 4 for row 9/50...\n",
      "Running Prompt 4 for row 10/50...\n",
      "Running Prompt 4 for row 11/50...\n",
      "Running Prompt 4 for row 12/50...\n",
      "Running Prompt 4 for row 13/50...\n",
      "Running Prompt 4 for row 14/50...\n",
      "Running Prompt 4 for row 15/50...\n",
      "Running Prompt 4 for row 16/50...\n",
      "Running Prompt 4 for row 17/50...\n",
      "Running Prompt 4 for row 18/50...\n",
      "Running Prompt 4 for row 19/50...\n",
      "Running Prompt 4 for row 20/50...\n",
      "Running Prompt 4 for row 21/50...\n",
      "Running Prompt 4 for row 22/50...\n",
      "Running Prompt 4 for row 23/50...\n",
      "Running Prompt 4 for row 24/50...\n",
      "Running Prompt 4 for row 25/50...\n",
      "Running Prompt 4 for row 26/50...\n",
      "Running Prompt 4 for row 27/50...\n",
      "Running Prompt 4 for row 28/50...\n",
      "Running Prompt 4 for row 29/50...\n",
      "Running Prompt 4 for row 30/50...\n",
      "Running Prompt 4 for row 31/50...\n",
      "Running Prompt 4 for row 32/50...\n",
      "Running Prompt 4 for row 33/50...\n",
      "Running Prompt 4 for row 34/50...\n",
      "Running Prompt 4 for row 35/50...\n",
      "Running Prompt 4 for row 36/50...\n",
      "Running Prompt 4 for row 37/50...\n",
      "Running Prompt 4 for row 38/50...\n",
      "Running Prompt 4 for row 39/50...\n",
      "Running Prompt 4 for row 40/50...\n",
      "Running Prompt 4 for row 41/50...\n",
      "Running Prompt 4 for row 42/50...\n",
      "Running Prompt 4 for row 43/50...\n",
      "Running Prompt 4 for row 44/50...\n",
      "Running Prompt 4 for row 45/50...\n",
      "Running Prompt 4 for row 46/50...\n",
      "Running Prompt 4 for row 47/50...\n",
      "Running Prompt 4 for row 48/50...\n",
      "Running Prompt 4 for row 49/50...\n",
      "Running Prompt 4 for row 50/50...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "p4_outputs = []\n",
    "\n",
    "for i, txt in enumerate(eval_df[\"text\"]):\n",
    "    print(f\"Running Prompt 4 for row {i+1}/{len(eval_df)}...\")\n",
    "    try:\n",
    "        out = run_prompt_4(txt)\n",
    "    except Exception as e:\n",
    "        print(\"Error on row\", i, \":\", e)\n",
    "        out = None\n",
    "        \n",
    "    p4_outputs.append(out)\n",
    "    \n",
    "    time.sleep(7)  # respect free-tier rate limit\n",
    "\n",
    "eval_df[\"p4_output\"] = p4_outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7cd79d61-e27d-4d07-95eb-f7ca70c5d2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.58, 1.0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p4_valid_flags = []\n",
    "p4_pred_stars = []\n",
    "\n",
    "for out in eval_df[\"p4_output\"]:\n",
    "    result, is_valid = parse_json_output(out)\n",
    "    p4_valid_flags.append(is_valid)\n",
    "    \n",
    "    if is_valid:\n",
    "        p4_pred_stars.append(result.get(\"predicted_stars\", None))\n",
    "    else:\n",
    "        p4_pred_stars.append(None)\n",
    "\n",
    "eval_df[\"p4_valid_json\"] = p4_valid_flags\n",
    "eval_df[\"p4_predicted_stars\"] = p4_pred_stars\n",
    "\n",
    "correct_p4 = (eval_df[\"stars\"] == eval_df[\"p4_predicted_stars\"]).sum()\n",
    "accuracy_p4 = correct_p4 / len(eval_df)\n",
    "json_validity_p4 = eval_df[\"p4_valid_json\"].mean()\n",
    "\n",
    "accuracy_p4, json_validity_p4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "483ac962-52a8-4907-b591-8dca21908e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Prompt': ['Prompt 1', 'Prompt 2', 'Prompt 3', 'Prompt 4'],\n",
       " 'Accuracy': [0.56, 0.52, 0.58, 0.58],\n",
       " 'JSON_validity': [1.0, 0.96, 1.0, 1.0]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = {\n",
    "    \"Prompt\": [\"Prompt 1\", \"Prompt 2\", \"Prompt 3\", \"Prompt 4\"],\n",
    "    \"Accuracy\": [accuracy_p1, accuracy_p2, accuracy_p3, accuracy_p4],\n",
    "    \"JSON_validity\": [json_validity_p1, json_validity_p2, json_validity_p3, json_validity_p4]\n",
    "}\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0049850-32af-4341-a904-c450f3f77cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
